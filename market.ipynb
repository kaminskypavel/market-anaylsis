{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection and storage process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed BDX (1973-02-21 to 2024-08-22):  12%|█▏        | 62/503 [00:33<05:02,  1.46stock/s]  $BRK.B: possibly delisted; no timezone found\n",
      "Processed BRO (1981-02-11 to 2024-08-22):  15%|█▌        | 77/503 [00:43<03:43,  1.91stock/s] $BF.B: possibly delisted; no price data found  (1d 1925-09-16 -> 2024-08-22)\n",
      "Processed ZTS (2013-02-01 to 2024-08-22): 100%|██████████| 503/503 [05:48<00:00,  1.44stock/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process completed. Total valid tickers: 501\n",
      "First 10 valid tickers: ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n",
      "\n",
      "Example data for MMM:\n",
      "Data from SQLite - First 5 rows:\n",
      "                        Date  Open      High       Low     Close  Volume  \\\n",
      "0  1962-01-02 00:00:00-05:00   0.0  0.587004  0.569739  0.574055  254509   \n",
      "1  1962-01-03 00:00:00-05:00   0.0  0.578371  0.564344  0.578371  505190   \n",
      "2  1962-01-04 00:00:00-05:00   0.0  0.588083  0.578371  0.578371  254509   \n",
      "3  1962-01-05 00:00:00-05:00   0.0  0.576213  0.561107  0.563265  376979   \n",
      "4  1962-01-08 00:00:00-05:00   0.0  0.564343  0.556790  0.560027  399942   \n",
      "\n",
      "   Dividends  Stock Splits  \n",
      "0        0.0           0.0  \n",
      "1        0.0           0.0  \n",
      "2        0.0           0.0  \n",
      "3        0.0           0.0  \n",
      "4        0.0           0.0  \n",
      "\n",
      "Data from SQLite - Last 5 rows:\n",
      "                            Date        Open        High         Low  \\\n",
      "15763  2024-08-16 00:00:00-04:00  126.739998  127.339996  126.019997   \n",
      "15764  2024-08-19 00:00:00-04:00  127.080002  127.849998  126.529999   \n",
      "15765  2024-08-20 00:00:00-04:00  126.989998  128.070007  126.879997   \n",
      "15766  2024-08-21 00:00:00-04:00  127.839996  129.990005  127.660004   \n",
      "15767  2024-08-22 00:00:00-04:00  129.100006  129.750000  128.300003   \n",
      "\n",
      "            Close   Volume  Dividends  Stock Splits  \n",
      "15763  127.050003  3812600        0.0           0.0  \n",
      "15764  127.080002  2243600        0.0           0.0  \n",
      "15765  127.699997  2792900        0.0           0.0  \n",
      "15766  129.229996  3664600        0.0           0.0  \n",
      "15767  128.509995  1872869        0.0           0.0  \n",
      "\n",
      "Total rows in SQLite: 15768\n",
      "\n",
      "Data from Parquet - First 5 rows:\n",
      "                           Open      High       Low     Close  Volume  \\\n",
      "Date                                                                    \n",
      "1962-01-02 00:00:00-05:00   0.0  0.587004  0.569739  0.574055  254509   \n",
      "1962-01-03 00:00:00-05:00   0.0  0.578371  0.564344  0.578371  505190   \n",
      "1962-01-04 00:00:00-05:00   0.0  0.588083  0.578371  0.578371  254509   \n",
      "1962-01-05 00:00:00-05:00   0.0  0.576213  0.561107  0.563265  376979   \n",
      "1962-01-08 00:00:00-05:00   0.0  0.564343  0.556790  0.560027  399942   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "1962-01-02 00:00:00-05:00        0.0           0.0  \n",
      "1962-01-03 00:00:00-05:00        0.0           0.0  \n",
      "1962-01-04 00:00:00-05:00        0.0           0.0  \n",
      "1962-01-05 00:00:00-05:00        0.0           0.0  \n",
      "1962-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Data from Parquet - Last 5 rows:\n",
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2024-08-16 00:00:00-04:00  126.739998  127.339996  126.019997  127.050003   \n",
      "2024-08-19 00:00:00-04:00  127.080002  127.849998  126.529999  127.080002   \n",
      "2024-08-20 00:00:00-04:00  126.989998  128.070007  126.879997  127.699997   \n",
      "2024-08-21 00:00:00-04:00  127.839996  129.990005  127.660004  129.229996   \n",
      "2024-08-22 00:00:00-04:00  129.100006  129.750000  128.300003  128.509995   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2024-08-16 00:00:00-04:00  3812600        0.0           0.0  \n",
      "2024-08-19 00:00:00-04:00  2243600        0.0           0.0  \n",
      "2024-08-20 00:00:00-04:00  2792900        0.0           0.0  \n",
      "2024-08-21 00:00:00-04:00  3664600        0.0           0.0  \n",
      "2024-08-22 00:00:00-04:00  1872869        0.0           0.0  \n",
      "\n",
      "Total rows in Parquet: 15768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Define the data directory\n",
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_and_store_data(tickers):\n",
    "    valid_tickers = []\n",
    "    \n",
    "    # Ensure data directory exists\n",
    "    ensure_dir(DATA_DIR)\n",
    "    \n",
    "    # Create subdirectories for SQLite and Parquet files\n",
    "    sqlite_dir = os.path.join(DATA_DIR, \"sqlite\")\n",
    "    parquet_dir = os.path.join(DATA_DIR, \"parquet\")\n",
    "    ensure_dir(sqlite_dir)\n",
    "    ensure_dir(parquet_dir)\n",
    "    \n",
    "    # SQLite database path\n",
    "    db_path = os.path.join(sqlite_dir, 'full_stock_data.sqlite')\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Create progress bar\n",
    "    pbar = tqdm(tickers, desc=\"Processing Stocks\", unit=\"stock\")\n",
    "    \n",
    "    for ticker in pbar:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Get all available history\n",
    "            history = stock.history(period=\"max\")\n",
    "            \n",
    "            if not history.empty:\n",
    "                valid_tickers.append(ticker)\n",
    "                \n",
    "                # Store in SQLite\n",
    "                history.to_sql(ticker, conn, if_exists='replace')\n",
    "                \n",
    "                # Store as Parquet\n",
    "                parquet_path = os.path.join(parquet_dir, f\"{ticker}.parquet\")\n",
    "                history.to_parquet(parquet_path)\n",
    "                \n",
    "                # Update progress bar description\n",
    "                pbar.set_description(f\"Processed {ticker} ({history.index[0].date()} to {history.index[-1].date()})\")\n",
    "            else:\n",
    "                pbar.set_description(f\"No data for {ticker}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            pbar.set_description(f\"Error with {ticker}: {str(e)[:50]}...\")  # Truncate long error messages\n",
    "    \n",
    "    conn.close()\n",
    "    return valid_tickers\n",
    "\n",
    "def read_data(ticker, source='sqlite'):\n",
    "    if source == 'sqlite':\n",
    "        db_path = os.path.join(DATA_DIR, \"sqlite\", 'full_stock_data.sqlite')\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            return pd.read_sql(f\"SELECT * FROM '{ticker}'\", conn)\n",
    "    elif source == 'parquet':\n",
    "        parquet_path = os.path.join(DATA_DIR, \"parquet\", f\"{ticker}.parquet\")\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid source. Choose 'sqlite' or 'parquet'.\")\n",
    "\n",
    "# Get S&P 500 components\n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500_tickers = sp500['Symbol'].tolist()\n",
    "\n",
    "print(\"Starting data collection and storage process...\")\n",
    "valid_tickers = get_and_store_data(sp500_tickers)\n",
    "\n",
    "print(f\"\\nProcess completed. Total valid tickers: {len(valid_tickers)}\")\n",
    "print(f\"First 10 valid tickers: {valid_tickers[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example of reading data\n",
    "if valid_tickers:\n",
    "    example_ticker = valid_tickers[0]\n",
    "    sqlite_data = read_data(example_ticker, 'sqlite')\n",
    "    parquet_data = read_data(example_ticker, 'parquet')\n",
    "    \n",
    "    print(f\"\\nExample data for {example_ticker}:\")\n",
    "    print(f\"Data from SQLite - First 5 rows:\")\n",
    "    print(sqlite_data.head())\n",
    "    print(f\"\\nData from SQLite - Last 5 rows:\")\n",
    "    print(sqlite_data.tail())\n",
    "    print(f\"\\nTotal rows in SQLite: {len(sqlite_data)}\")\n",
    "    \n",
    "    print(f\"\\nData from Parquet - First 5 rows:\")\n",
    "    print(parquet_data.head())\n",
    "    print(f\"\\nData from Parquet - Last 5 rows:\")\n",
    "    print(parquet_data.tail())\n",
    "    print(f\"\\nTotal rows in Parquet: {len(parquet_data)}\")\n",
    "else:\n",
    "    print(\"No valid tickers found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
